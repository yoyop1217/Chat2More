import os
import asyncio
import openai
from dotenv import load_dotenv
import httpx
from openai import AsyncOpenAI
import traceback
import json
import gradio as gr
from models_list import STIMA_MODELS

model_list = list(STIMA_MODELS.keys())

# 1ï¸âƒ£ ENV
load_dotenv()
TIMEOUT = 60
## 1-1. STIMA_env
STIMA_KEY = os.getenv("STIMA_API_KEY")
STIMA_URL = "https://api.stima.tech/v1"


# 2ï¸âƒ£ SET
## 2-1. Client
def get_client():
    return AsyncOpenAI(
        api_key=STIMA_KEY,
        base_url=STIMA_URL,
        timeout=TIMEOUT
    )

# 2-2. Rewirte
async def rewrite_once(model_key, text, system_prompt, temp):
    try:
        if not text or not text.strip():
            return "âš ï¸ è«‹è¼¸å…¥æ–‡å­—"
        
        if model_key not in STIMA_MODELS:
            return f"âš ï¸ æ‰¾ä¸åˆ°æ¨¡å‹ {model_key}"
        
        _, full_id = STIMA_MODELS[model_key]
        client = get_client()
        
        # Build Messages
        messages = [
            {"role": "system", "content": system_prompt or "You are a helpful assistant."},
            {"role": "user", "content": text}
        ]
        
        print(f"å‘¼å«æ¨¡å‹: {full_id}")
        print(f"è¨Šæ¯å…§å®¹: {messages}")
        
        # Called API
        try:
            resp = await client.chat.completions.create(
                model=full_id,
                messages=messages,
                temperature=temp,
                max_tokens=2000,
                timeout=60
            )
            
            print(f"API å›æ‡‰é¡å‹: {type(resp)}")
            print(f"API å›æ‡‰å…§å®¹: {resp}")
            
            # Check the return
            if isinstance(resp, str):
                try:
                    resp_data = json.loads(resp)
                    if 'error' in resp_data:
                        return f"âš ï¸ API éŒ¯èª¤ï¼š{resp_data['error']}"
                    return f"âš ï¸ æœªé æœŸçš„å­—ä¸²å›æ‡‰ï¼š{resp}"
                except json.JSONDecodeError:
                    return f"âš ï¸ ç„¡æ³•è§£æçš„å›æ‡‰ï¼š{resp}"
            
            if not hasattr(resp, 'choices'):
                return f"âš ï¸ API å›æ‡‰æ ¼å¼ä¸æ­£ç¢º (ç¼ºå°‘ choices)\nå›æ‡‰é¡å‹: {type(resp)}\nå›æ‡‰å…§å®¹: {str(resp)}"
            
            if not resp.choices or len(resp.choices) == 0:
                return "âš ï¸ API å›æ‡‰ä¸­æ²’æœ‰é¸é …"
            
            choice = resp.choices[0]
            if not hasattr(choice, 'message'):
                return f"âš ï¸ API å›æ‡‰æ ¼å¼ä¸æ­£ç¢º (ç¼ºå°‘ message)\né¸é …å…§å®¹: {str(choice)}"
            
            message = choice.message
            if not hasattr(message, 'content'):
                return f"âš ï¸ API å›æ‡‰æ ¼å¼ä¸æ­£ç¢º (ç¼ºå°‘ content)\nè¨Šæ¯å…§å®¹: {str(message)}"
            
            # Get Content
            content = message.content
            if content is None:
                return "âš ï¸ æ¨¡å‹å›æ‡‰ç‚ºç©º"
            
            return content.strip()
            
        except openai.APIConnectionError as e:
            return f"âš ï¸ é€£ç·šéŒ¯èª¤ï¼šç„¡æ³•é€£æ¥åˆ° API æœå‹™\nè©³ç´°ï¼š{str(e)}"
        except openai.RateLimitError as e:
            return f"âš ï¸ é€Ÿç‡é™åˆ¶ï¼šAPI è«‹æ±‚éæ–¼é »ç¹\nè©³ç´°ï¼š{str(e)}"
        except openai.APIStatusError as e:
            return f"âš ï¸ API éŒ¯èª¤ (ç‹€æ…‹ç¢¼ {e.status_code})ï¼š{e.message}\nè©³ç´°ï¼š{str(e)}"
        except openai.APITimeoutError as e:
            return f"âš ï¸ è¶…æ™‚éŒ¯èª¤ï¼šAPI å›æ‡‰æ™‚é–“éé•·\nè©³ç´°ï¼š{str(e)}"
        except httpx.ConnectError as e:
            return f"âš ï¸ ç¶²è·¯é€£ç·šéŒ¯èª¤ï¼šç„¡æ³•é€£æ¥åˆ°ä¼ºæœå™¨\nè©³ç´°ï¼š{str(e)}"
        except httpx.TimeoutException as e:
            return f"âš ï¸ ç¶²è·¯è¶…æ™‚ï¼šè«‹æ±‚è¶…æ™‚\nè©³ç´°ï¼š{str(e)}"
        except Exception as e:
            error_detail = traceback.format_exc()
            return f"âš ï¸ API å‘¼å«éŒ¯èª¤ï¼š{type(e).__name__}\néŒ¯èª¤ï¼š{str(e)}\n\nè©³ç´°è¿½è¹¤:\n{error_detail}"
            
    except Exception as e:
        error_detail = traceback.format_exc()
        return f"âš ï¸ æœªé æœŸçš„éŒ¯èª¤ï¼š{type(e).__name__}\n{str(e)}\n\nè©³ç´°è³‡è¨Š:\n{error_detail}"
    

# 2-3. Batch Rewrite
def rewrite_batch(text, model1, model2, model3, sys_prompt, temp):
    # check empty
    if not text or not text.strip():
        return ("è«‹è¼¸å…¥è¦æ”¹å¯«çš„æ–‡å­—", "è«‹è¼¸å…¥è¦æ”¹å¯«çš„æ–‡å­—", "è«‹è¼¸å…¥è¦æ”¹å¯«çš„æ–‡å­—")
    
    async def _run():
        # set up tasks, allow concurrent execution
        tasks = [
            rewrite_once(model1, text, sys_prompt, temp),
            rewrite_once(model2, text, sys_prompt, temp),
            rewrite_once(model3, text, sys_prompt, temp)
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # process results
        processed_results = []
        model_names = [model1, model2, model3]
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                # If an exception occurred, format it nicely
                error_msg = f"æ¨¡å‹ {model_names[i]} åŸ·è¡ŒéŒ¯èª¤ï¼š\n{type(result).__name__}\n{str(result)}"
                processed_results.append(error_msg)
            else:
                processed_results.append(result)
        
        return processed_results
    
    try:
        return asyncio.run(_run())
    except Exception as e:
        error_msg = f"æ‰¹æ¬¡åŸ·è¡ŒéŒ¯èª¤ï¼š{type(e).__name__}\n{str(e)}"
        return (error_msg, error_msg, error_msg)


# 3ï¸âƒ£ Test API Connection
def test_api_connection():
    async def _test():
        try:
            client = get_client()
            # Use a common model for testing
            resp = await client.chat.completions.create(
                model="gpt-4.1-nano", # A small, fast, and cost-effective GPT-4 variant
                messages=[{"role": "user", "content": "Hello"}],
                max_tokens=10,
                timeout=10
            )
            return f"API é€£ç·šæ­£å¸¸\nå›æ‡‰é¡å‹: {type(resp)}"
        except Exception as e:
            return f"API é€£ç·šæ¸¬è©¦å¤±æ•—: {type(e).__name__}\n{str(e)}"
    
    try:
        return asyncio.run(_test())
    except Exception as e:
        return f"é€£ç·šæ¸¬è©¦åŸ·è¡ŒéŒ¯èª¤: {type(e).__name__}\n{str(e)}"

with gr.Blocks(theme=gr.themes.Soft(), title="Chat-2-More") as demo:
    gr.Markdown("# ğŸ“ æ¯”è¼ƒå¤šç¨®æ¨¡å‹çš„è¼¸å‡ºçµæœï¼ˆwith StimaAPIï¼‰")
    
    # ä¸»è¦åŠŸèƒ½å€åŸŸ
    src = gr.Textbox(
        label="è¼¸å…¥å­—å¥", 
        lines=8, 
        placeholder="å¦‚ï¼šè«‹å¹«æˆ‘è§£é‡‹ä»€éº¼æ˜¯é‡å­é›»è…¦ï¼Ÿ",
        value=""
    )
    
    sys_prompt = gr.Textbox(
        label="è‡ªè¨‚ç³»çµ±æç¤º (å¯ç©ºç™½)", 
        placeholder="å¦‚ï¼šç”¨å¤§å­¸ç”Ÿçš„å£å»å›ç­”",
        value=""
    )

    temp = gr.Slider(
        0.0, 1.0, 
        value=0.7,
        step=0.05, 
        label="Temperature (0=ä¿å®ˆ, 1=å‰µæ„)"
    )
    
    with gr.Row():
        # 
        default_idx1 = min(4, len(model_list)-1) if len(model_list) > 4 else 0
        default_idx2 = min(41, len(model_list)-1) if len(model_list) > 41 else min(1, len(model_list)-1)
        default_idx3 = min(151, len(model_list)-1) if len(model_list) > 151 else min(2, len(model_list)-1)
        
        dd1 = gr.Dropdown(
            model_list, 
            value=model_list[default_idx1] if model_list else None, 
            label="æ¨¡å‹ 1"
        )
        dd2 = gr.Dropdown(
            model_list, 
            value=model_list[default_idx2] if model_list else None, 
            label="æ¨¡å‹ 2"
        )
        dd3 = gr.Dropdown(
            model_list, 
            value=model_list[default_idx3] if model_list else None, 
            label="æ¨¡å‹ 3"
        )

    btn = gr.Button("ğŸŒŸ é–‹å§‹æŸ¥è©¢", variant="primary")

    with gr.Row():
        out1 = gr.Textbox(label="æ¨¡å‹ 1 è¼¸å‡º", lines=20)
        out2 = gr.Textbox(label="æ¨¡å‹ 2 è¼¸å‡º", lines=20)
        out3 = gr.Textbox(label="æ¨¡å‹ 3 è¼¸å‡º", lines=20)  

if __name__ == "__main__":
    # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
    if not STIMA_KEY:
        print("âš ï¸ STIMA_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®šï¼")
    else:
        print("âœ… STIMA_API_KEY å·²è¨­å®š")
    
    # æª¢æŸ¥æ¨¡å‹æ¸…å–®
    if not model_list:
        print("âš ï¸ models_list.py ä¸­æ²’æœ‰æ‰¾åˆ°æ¨¡å‹ï¼")
    else:
        print(f"âœ… æ‰¾åˆ° {len(model_list)} å€‹æ¨¡å‹")
    
    demo.launch(server_name="0.0.0.0", server_port=7860)
